Validando modelos com todas as características
Imprimindo resultados da abordagem por validação cruzada para o <class 'sklearn.dummy.DummyClassifier'>
F-measure média: 47.62
Intervalo de f-measure: [44.85, 50.39]
Selecionando-se as características com SelectKBest(k=5,
            score_func=<function mutual_info_classif at 0x0000022D70C250D0>)
Tempo do modelo <class 'sklearn.dummy.DummyClassifier'>: 1
F-measure média: 47.62
Intervalo de f-measure: [44.85, 50.39]
Imprimindo resultados da abordagem por validação cruzada para o <class 'sklearn.neighbors._classification.KNeighborsClassifier'>
F-measure média: 67.42
Intervalo de f-measure: [65.65, 69.19]
Selecionando-se as características com SelectKBest(k=5,
            score_func=<function mutual_info_classif at 0x0000022D70C250D0>)
Tempo do modelo <class 'sklearn.neighbors._classification.KNeighborsClassifier'>: 4
F-measure média: 74.70
Intervalo de f-measure: [73.63, 75.78]
Imprimindo resultados da abordagem por validação cruzada para o <class 'sklearn.tree._classes.DecisionTreeClassifier'>
F-measure média: 69.29
Intervalo de f-measure: [67.69, 70.89]
Selecionando-se as características com RFECV(cv=5, estimator=DecisionTreeClassifier(), scoring='f1_micro')
Tempo do modelo <class 'sklearn.tree._classes.DecisionTreeClassifier'>: 4
F-measure média: 69.40
Intervalo de f-measure: [67.75, 71.04]
Imprimindo resultados da abordagem por validação cruzada para o <class 'sklearn.naive_bayes.GaussianNB'>
F-measure média: 52.54
Intervalo de f-measure: [48.47, 56.60]
Selecionando-se as características com SelectKBest(k=5,
            score_func=<function mutual_info_classif at 0x0000022D70C250D0>)
Tempo do modelo <class 'sklearn.naive_bayes.GaussianNB'>: 1
F-measure média: 51.56
Intervalo de f-measure: [47.19, 55.93]
Imprimindo resultados da abordagem por validação cruzada para o <class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'>
F-measure média: 77.42
Intervalo de f-measure: [76.65, 78.19]
Selecionando-se as características com RFECV(cv=5, estimator=AdaBoostClassifier(n_estimators=100), scoring='f1_micro')
Tempo do modelo <class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'>: 58
F-measure média: 77.42
Intervalo de f-measure: [76.66, 78.18]
Imprimindo resultados da abordagem por validação cruzada para o <class 'sklearn.ensemble._forest.RandomForestClassifier'>
F-measure média: 77.68
Intervalo de f-measure: [76.61, 78.75]
Selecionando-se as características com RFECV(cv=5, estimator=RandomForestClassifier(), scoring='f1_micro')
Tempo do modelo <class 'sklearn.ensemble._forest.RandomForestClassifier'>: 111
F-measure média: 77.79
Intervalo de f-measure: [76.75, 78.84]
Imprimindo resultados da abordagem por validação cruzada para o <class 'sklearn.ensemble._bagging.BaggingClassifier'>
F-measure média: 52.79
Intervalo de f-measure: [49.07, 56.51]
Selecionando-se as características com SelectKBest(k=5,
            score_func=<function mutual_info_classif at 0x0000022D70C250D0>)
Tempo do modelo <class 'sklearn.ensemble._bagging.BaggingClassifier'>: 6
F-measure média: 51.88
Intervalo de f-measure: [47.60, 56.17]
Imprimindo resultados da abordagem holdout para o <class 'sklearn.dummy.DummyClassifier'>
F-measure de 93.34%
Selecionando-se as características com SelectKBest(k=5,
            score_func=<function mutual_info_classif at 0x0000022D70C250D0>)
F-measure de 93.34%
Tempo do modelo <class 'sklearn.dummy.DummyClassifier'>: 0
Imprimindo resultados da abordagem holdout para o <class 'sklearn.neighbors._classification.KNeighborsClassifier'>
F-measure de 74.77%
Selecionando-se as características com SelectKBest(k=5,
            score_func=<function mutual_info_classif at 0x0000022D70C250D0>)
F-measure de 75.91%
Tempo do modelo <class 'sklearn.neighbors._classification.KNeighborsClassifier'>: 7
Imprimindo resultados da abordagem holdout para o <class 'sklearn.tree._classes.DecisionTreeClassifier'>
F-measure de 69.08%
Selecionando-se as características com RFE(estimator=DecisionTreeClassifier(), n_features_to_select=5)
F-measure de 64.05%
Tempo do modelo <class 'sklearn.tree._classes.DecisionTreeClassifier'>: 0
Imprimindo resultados da abordagem holdout para o <class 'sklearn.naive_bayes.GaussianNB'>
F-measure de 93.22%
Selecionando-se as características com SelectKBest(k=5,
            score_func=<function mutual_info_classif at 0x0000022D70C250D0>)
F-measure de 93.47%
Tempo do modelo <class 'sklearn.naive_bayes.GaussianNB'>: 0
Imprimindo resultados da abordagem holdout para o <class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'>
F-measure de 79.45%
Selecionando-se as características com RFE(estimator=AdaBoostClassifier(n_estimators=100), n_features_to_select=5)
F-measure de 72.16%
Tempo do modelo <class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'>: 6
Imprimindo resultados da abordagem holdout para o <class 'sklearn.ensemble._forest.RandomForestClassifier'>
F-measure de 78.15%
Selecionando-se as características com RFE(estimator=RandomForestClassifier(), n_features_to_select=5)
F-measure de 75.19%
Tempo do modelo <class 'sklearn.ensemble._forest.RandomForestClassifier'>: 12
Imprimindo resultados da abordagem holdout para o <class 'sklearn.ensemble._bagging.BaggingClassifier'>
F-measure de 93.22%
Selecionando-se as características com SelectKBest(k=5,
            score_func=<function mutual_info_classif at 0x0000022D70C250D0>)
F-measure de 93.45%
Tempo do modelo <class 'sklearn.ensemble._bagging.BaggingClassifier'>: 3
Validando modelos sem as características correlacionadas
Imprimindo resultados da abordagem por validação cruzada para o <class 'sklearn.dummy.DummyClassifier'>
F-measure média: 47.62
Intervalo de f-measure: [44.85, 50.39]
Selecionando-se as características com SelectKBest(k=5,
            score_func=<function mutual_info_classif at 0x0000022D70C250D0>)
Tempo do modelo <class 'sklearn.dummy.DummyClassifier'>: 0
F-measure média: 47.62
Intervalo de f-measure: [44.85, 50.39]
Imprimindo resultados da abordagem por validação cruzada para o <class 'sklearn.neighbors._classification.KNeighborsClassifier'>
F-measure média: 61.01
Intervalo de f-measure: [59.60, 62.41]
Selecionando-se as características com SelectKBest(k=5,
            score_func=<function mutual_info_classif at 0x0000022D70C250D0>)
Tempo do modelo <class 'sklearn.neighbors._classification.KNeighborsClassifier'>: 3
F-measure média: 55.90
Intervalo de f-measure: [54.84, 56.96]
Imprimindo resultados da abordagem por validação cruzada para o <class 'sklearn.tree._classes.DecisionTreeClassifier'>
F-measure média: 61.29
Intervalo de f-measure: [56.99, 65.59]
Selecionando-se as características com RFECV(cv=5, estimator=DecisionTreeClassifier(), scoring='f1_micro')
Tempo do modelo <class 'sklearn.tree._classes.DecisionTreeClassifier'>: 2
F-measure média: 60.34
Intervalo de f-measure: [55.36, 65.32]
Imprimindo resultados da abordagem por validação cruzada para o <class 'sklearn.naive_bayes.GaussianNB'>
F-measure média: 53.72
Intervalo de f-measure: [42.87, 64.57]
Selecionando-se as características com SelectKBest(k=5,
            score_func=<function mutual_info_classif at 0x0000022D70C250D0>)
Tempo do modelo <class 'sklearn.naive_bayes.GaussianNB'>: 0
F-measure média: 51.99
Intervalo de f-measure: [44.32, 59.66]
Imprimindo resultados da abordagem por validação cruzada para o <class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'>
F-measure média: 66.93
Intervalo de f-measure: [61.46, 72.39]
Selecionando-se as características com RFECV(cv=5, estimator=AdaBoostClassifier(n_estimators=100), scoring='f1_micro')
Tempo do modelo <class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'>: 42
F-measure média: 66.93
Intervalo de f-measure: [61.46, 72.39]
Imprimindo resultados da abordagem por validação cruzada para o <class 'sklearn.ensemble._forest.RandomForestClassifier'>
F-measure média: 70.46
Intervalo de f-measure: [67.92, 73.01]
Selecionando-se as características com RFECV(cv=5, estimator=RandomForestClassifier(), scoring='f1_micro')
Tempo do modelo <class 'sklearn.ensemble._forest.RandomForestClassifier'>: 82
F-measure média: 70.02
Intervalo de f-measure: [66.76, 73.27]
Imprimindo resultados da abordagem por validação cruzada para o <class 'sklearn.ensemble._bagging.BaggingClassifier'>
F-measure média: 57.19
Intervalo de f-measure: [46.28, 68.10]
Selecionando-se as características com SelectKBest(k=5,
            score_func=<function mutual_info_classif at 0x0000022D70C250D0>)
Tempo do modelo <class 'sklearn.ensemble._bagging.BaggingClassifier'>: 5
F-measure média: 57.55
Intervalo de f-measure: [49.66, 65.44]
Imprimindo resultados da abordagem holdout para o <class 'sklearn.dummy.DummyClassifier'>
F-measure de 93.34%
Selecionando-se as características com SelectKBest(k=5,
            score_func=<function mutual_info_classif at 0x0000022D70C250D0>)
F-measure de 93.34%
Tempo do modelo <class 'sklearn.dummy.DummyClassifier'>: 0
Imprimindo resultados da abordagem holdout para o <class 'sklearn.neighbors._classification.KNeighborsClassifier'>
F-measure de 67.25%
Selecionando-se as características com SelectKBest(k=5,
            score_func=<function mutual_info_classif at 0x0000022D70C250D0>)
F-measure de 66.65%
Tempo do modelo <class 'sklearn.neighbors._classification.KNeighborsClassifier'>: 7
Imprimindo resultados da abordagem holdout para o <class 'sklearn.tree._classes.DecisionTreeClassifier'>
F-measure de 66.38%
Selecionando-se as características com RFE(estimator=DecisionTreeClassifier(), n_features_to_select=5)
F-measure de 63.55%
Tempo do modelo <class 'sklearn.tree._classes.DecisionTreeClassifier'>: 0
Imprimindo resultados da abordagem holdout para o <class 'sklearn.naive_bayes.GaussianNB'>
F-measure de 84.30%
Selecionando-se as características com SelectKBest(k=5,
            score_func=<function mutual_info_classif at 0x0000022D70C250D0>)
F-measure de 88.57%
Tempo do modelo <class 'sklearn.naive_bayes.GaussianNB'>: 0
Imprimindo resultados da abordagem holdout para o <class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'>
F-measure de 76.53%
Selecionando-se as características com RFE(estimator=AdaBoostClassifier(n_estimators=100), n_features_to_select=5)
F-measure de 73.35%
Tempo do modelo <class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'>: 5
Imprimindo resultados da abordagem holdout para o <class 'sklearn.ensemble._forest.RandomForestClassifier'>
F-measure de 76.17%
Selecionando-se as características com RFE(estimator=RandomForestClassifier(), n_features_to_select=5)
F-measure de 75.55%
Tempo do modelo <class 'sklearn.ensemble._forest.RandomForestClassifier'>: 9
Imprimindo resultados da abordagem holdout para o <class 'sklearn.ensemble._bagging.BaggingClassifier'>
F-measure de 84.70%
Selecionando-se as características com SelectKBest(k=5,
            score_func=<function mutual_info_classif at 0x0000022D70C250D0>)
F-measure de 88.79%
Tempo do modelo <class 'sklearn.ensemble._bagging.BaggingClassifier'>: 2